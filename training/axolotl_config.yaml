# CLI-Tuner Phase 2 Training Configuration
# QLoRA fine-tuning of Qwen2.5-Coder-7B-Instruct
# Target: 24GB consumer GPU (RTX 3090/4090) or A100 80GB

# ============================================================================
# BASE MODEL
# ============================================================================
base_model: Qwen/Qwen2.5-Coder-7B-Instruct
model_type: AutoModelForCausalLM
tokenizer_type: AutoTokenizer
trust_remote_code: false

# ============================================================================
# QUANTIZATION (4-bit NF4 for memory efficiency)
# ============================================================================
load_in_4bit: true
adapter: lora

# ============================================================================
# LORA CONFIGURATION
# ============================================================================
lora_model_dir: null
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules:
  - q_proj
  - v_proj
  - k_proj
  - o_proj
lora_target_linear: false
lora_fan_in_fan_out: false

# ============================================================================
# DATASET
# ============================================================================
datasets:
  - path: data/processed/train.jsonl
    type: completion
    field: text

# Validation dataset (using separate file from Phase 1)
val_set_size: 0.0 # Don't split from train - use test_datasets instead

test_datasets:
  - path: data/processed/val.jsonl
    type: completion
    field: text

# ============================================================================
# SEQUENCE CONFIGURATION
# ============================================================================
sequence_len: 512
sample_packing: false
pad_to_sequence_len: true

# ============================================================================
# BATCH SIZE & GRADIENT ACCUMULATION
# ============================================================================
micro_batch_size: 1
gradient_accumulation_steps: 4
eval_batch_size: 1

# Effective batch size: micro_batch_size Ã— gradient_accumulation_steps = 4

# ============================================================================
# TRAINING DURATION
# ============================================================================
num_epochs: 1
max_steps: 500 # ~1.4 epochs for 1,388 train examples

# ============================================================================
# OPTIMIZER & LEARNING RATE
# ============================================================================
optimizer: adamw_bnb_8bit
lr_scheduler: cosine
learning_rate: 0.0002
warmup_steps: 50 # 10% of max_steps

# ============================================================================
# PRECISION & MEMORY OPTIMIZATION
# ============================================================================
bf16: true
fp16: false
tf32: false
gradient_checkpointing: true

# ============================================================================
# CHECKPOINTING
# ============================================================================
output_dir: models/checkpoints
save_strategy: steps
save_steps: 100
save_total_limit: 3 # Keep last 3 checkpoints only

# ============================================================================
# EVALUATION
# ============================================================================
eval_strategy: steps
eval_steps: 50

# ============================================================================
# LOGGING
# ============================================================================
logging_steps: 10

# ============================================================================
# WEIGHTS & BIASES
# ============================================================================
wandb_project: SecureCLI-Training
wandb_run_name: phase2-training-v2
wandb_log_model: "false"

# ============================================================================
# SPECIAL TOKENS (Qwen format - already in tokenizer)
# ============================================================================
special_tokens: {}
